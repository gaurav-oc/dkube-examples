{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set appropriate sys path and import kfp pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dkube/.local/lib/python3.6/site-packages/\")\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List existing pipeline experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dkube ChexNet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dell_experiment = client.create_experiment(name='dell-chexnet-pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define e2e ChexNet Pipeline with Dkube components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "import json\n",
    "import time\n",
    "\n",
    "dkube_preprocess_op = components.load_component_from_file(\n",
    "    \"../components/preprocess/component.yaml\")\n",
    "dkube_training_op = components.load_component_from_file(\n",
    "    \"../components/training/component.yaml\")\n",
    "dkube_serving_op = components.load_component_from_file(\n",
    "    \"../components/serving/component.yaml\")\n",
    "dkube_viewer_op = components.load_component_from_file(\n",
    "    \"../components/viewer/component.yaml\")\n",
    "\n",
    "# constants\n",
    "WORKSPACE = \"chexnet-ws\"\n",
    "# input dataset for preprocessing\n",
    "PREPROCESS_DATASET = \"chexnet\"\n",
    "TARGET_DATASET = \"chexnet-preprocessed\"\n",
    "STEPS = 20000  # max no of steps\n",
    "EPOCHS = 1\n",
    "BATCHSIZE = 32\n",
    "SERVING_EXAMPLE = \"chestnet\"\n",
    "\n",
    "\n",
    "@dsl.pipeline(name='Dkube-ChexNet-pl',\n",
    "              description=('Dell ChexNet pipeline'\n",
    "                           'with dkube components'))\n",
    "def d3pipeline(\n",
    "    auth_token,\n",
    "    preprocess_container=json.dumps(\n",
    "        {'image': 'docker.io/ocdr/dkube-datascience-tf-cpu:v1.14'}),\n",
    "    preprocess_script=\"python preprocess.py\",\n",
    "    preprocess_program=WORKSPACE,\n",
    "    preprocess_target_name=TARGET_DATASET,  # dataset\n",
    "    # RAW dataset containing zip files of Chest X-Rays from NIH\n",
    "    preprocess_datasets=json.dumps([PREPROCESS_DATASET]),\n",
    "    training_container=json.dumps(\n",
    "        {'image': 'docker.io/ocdr/dkube-datascience-tf-gpu:v1.14'}),\n",
    "    training_program=WORKSPACE,\n",
    "    training_script=\"python model.py\",\n",
    "    training_gpus=1,\n",
    "    training_envs=json.dumps([{\"steps\": STEPS,\n",
    "                               \"epochs\": EPOCHS,\n",
    "                               \"batchsize\": BATCHSIZE}])):\n",
    "\n",
    "    # preprocessing stage\n",
    "    preprocess = dkube_preprocess_op(auth_token, preprocess_target_name,\n",
    "                                     preprocess_container,\n",
    "                                     program=preprocess_program,\n",
    "                                     datasets=preprocess_datasets,\n",
    "                                     run_script=preprocess_script)\n",
    "\n",
    "    # training stage\n",
    "    preprocess_dataset_name = json.dumps([str(preprocess_target_name)])\n",
    "    train = dkube_training_op(auth_token, training_container,\n",
    "                              program=training_program,\n",
    "                              run_script=training_script,\n",
    "                              datasets=preprocess_dataset_name,\n",
    "                              ngpus=training_gpus,\n",
    "                              envs=training_envs).after(preprocess)\n",
    "    # serving stage\n",
    "    serving = dkube_serving_op(\n",
    "        auth_token, train.outputs['artifact']).after(train)\n",
    "    # inference stage\n",
    "    inference = dkube_viewer_op(\n",
    "        auth_token, serving.outputs['servingurl'],\n",
    "        SERVING_EXAMPLE, viewtype='inference').after(serving)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and generate tar ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(d3pipeline, 'dell-chexnet-pl.tar.gz')\n",
    "# Upload this generated tarball into the Pipelines UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Click the dkube-training stage to see the enhanced Dkube Datascience dashboard, metrics and graphs. Click the dkube-webapp stage for the simple UI to test the model predecitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "run = client.run_pipeline(dell_experiment.id, 'dell-chexnet-pl', 'dell-chexnet-pl.tar.gz', params={'auth_token': os.getenv(\"ACCESS_TOKEN\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
