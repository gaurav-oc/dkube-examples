{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RELEASE_VERSION=0.1.18\n",
    "!pip install https://storage.googleapis.com/ml-pipeline/release/${RELEASE_VERSION}/kfp.tar.gz --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0408 05:50:36.929502 139839822395200 deprecation_wrapper.py:119] From /home/dkube/.ipython/extensions/myextension.py:9: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dkube pipeline experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/dcd544c8-860d-4172-8370-cbfbff07b41e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "parabricks_experiment = client.create_experiment(name='human-par-pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import os\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "dkube_training_op           = components.load_component_from_file(\"training-component.yaml\")\n",
    "\n",
    "description = \"\"\"Given one or more pairs of fastq files, you can run the human_par\n",
    "pipeline workflow to generate output including BAM, recal, and variants called with\n",
    "proper pseudoautosomal region ploidy values.\n",
    "\"\"\"\n",
    "@dsl.pipeline(\n",
    "    name='human-par-pipeline',\n",
    "    description=description\n",
    ")\n",
    "def human_par_pipeline(\n",
    "    auth_token  = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\"),\n",
    "    container = json.dumps({'image':'docker.io/ocdr/parabricks:v2.5.0', 'username':'', 'password': ''}),\n",
    "    workspace = \"parabricks\",\n",
    "    datasets = json.dumps([\"parabricks-sample\"]),\n",
    "    ref = \"Ref/Homo_sapiens_assembly38.fasta\",\n",
    "    in_fq_1 = \"Data/sample_1.fq.gz\",\n",
    "    in_fq_2 = \"Data/sample_2.fq.gz\",\n",
    "    knownSites = \"Ref/Homo_sapiens_assembly38.known_indels.vcf.gz\",\n",
    "    range_male = \"1-10\",\n",
    "    range_female = \"150-250\",\n",
    "    sample_sex = \"male\",    \n",
    "    #Request gpus as needed. Val 0 means no gpu,\n",
    "    num_gpus=2):\n",
    "\n",
    "    #Script to run inside the training container\n",
    "    args = \"\"\"--ref $DKUBE_INPUT_DATASETS/{} --in-fq $DKUBE_INPUT_DATASETS/{} $DKUBE_INPUT_DATASETS/{} \\\n",
    "            --knownSites $DKUBE_INPUT_DATASETS/{} --range-male {} --range-female {} --sample-sex {} \\\n",
    "            --out-bam $DKUBE_INPUT_DATASETS/output.bam --out-variants $DKUBE_INPUT_DATASETS/output.vcf \\\n",
    "            --out-recal-file $DKUBE_INPUT_DATASETS/report.txt --num-gpus {}\"\"\".format(\n",
    "        ref, in_fq_1, in_fq_2,knownSites, range_male, range_female, sample_sex, num_gpus\n",
    "    )\n",
    "    \n",
    "    #Path to NVIDIA parabricks license. Upload it to workspace\"\n",
    "    license_file = \"license.bin\"\n",
    "    run_script=\"/INSTALL/pbrun human_par \" + args + \" --license-file \" + license_file + \"|| true\"\n",
    "    \n",
    "    dkube_training_op(auth_token, container, program=workspace, run_script=run_script, datasets=datasets, ngpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and generate tar ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(human_par_pipeline, 'human_par_pl.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/60f39e9a-e5b7-486b-975b-70c664307434\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = client.run_pipeline(parabricks_experiment.id, 'human-par-pipeline', 'human_par_pl.tar.gz', params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
