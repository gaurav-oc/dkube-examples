{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKSPACE STRUCTURE FOR PET DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pets_detection/\n",
    "        ├─ data/\n",
    "        │    ├── images/\n",
    "        │    │      ├── pet (1).jpg\n",
    "        │    │      ├── pet (2).jpg\n",
    "        │    │      └── ...\n",
    "        │    ├── annotations/\n",
    "        │    │      ├── pet (1).xml\n",
    "        │    │      ├── pet (2).xml\n",
    "        │    │      └── ...\n",
    "        |         |── train.record\n",
    "        |    ├── test_images/\n",
    "        │    │      ├── pet (10).jpg\n",
    "        │    │      ├── pet (20).jpg\n",
    "        │    │      └── ...\n",
    "        │    ├── test_annotations/\n",
    "        │    │      ├── pet (10).xml\n",
    "        │    │      ├── pet (20).xml\n",
    "        │    │      └── ...     \n",
    "        |    |    |── test.record\n",
    "        │    \n",
    "        ├─ generate_tfrecord.py\n",
    "        ├── pets_label_map.pbtxt\n",
    "        ├── model_main_tf2.py\n",
    "        ├── pipeline.config\n",
    "        ├── ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\n",
    "                ├── checkpoint\n",
    "                ├── saved_model\n",
    "                ├── pipeline.config     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NECESSARY IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import six.moves.urllib as urllib\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'pets_detection' created\n"
     ]
    }
   ],
   "source": [
    "# Directory for pets\n",
    "directory = \"pets_detection\"\n",
    "  \n",
    "# Parent Directory path \n",
    "parent_dir = \"/home/dkube/work/workspace\"\n",
    "  \n",
    "# Path \n",
    "path = os.path.join(parent_dir, directory) \n",
    "\n",
    "os.mkdir(path) \n",
    "print(\"Directory '%s' created\" %directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the workspace structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'data' created\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/home/dkube/work/workspace/pets_detection\"\n",
    "data_path=\"data\"\n",
    "\n",
    "data_dir_path = os.path.join(base_path,data_path) \n",
    "\n",
    "os.mkdir(data_dir_path) \n",
    "print(\"Directory '%s' created\" %data_path)\n",
    "\n",
    "##### Creating the test-images and test-annotations folder ######\n",
    "\n",
    "os.mkdir(data_dir_path+\"/test_images\") \n",
    "os.mkdir(data_dir_path+\"/test_annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dkube/work/workspace/pets_detection/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(data_dir):\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(\"http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\",data_dir +\"/annotations.tar.gz\")\n",
    "    opener.retrieve(\"http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\", data_dir + \"/images.tar.gz\")\n",
    "    print(\"Downloaded and saved the dataset. Location: \",data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved the dataset. Location:  /home/dkube/work/workspace/pets_detection/data\n"
     ]
    }
   ],
   "source": [
    "download(data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the downloaded files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data_dir_path):\n",
    "    print(data_dir_path)\n",
    "    files = [os.path.join(data_dir_path, f) for f in os.listdir(data_dir_path) if f.endswith('tar.gz')]\n",
    "    print(files)\n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall(data_dir_path)\n",
    "        tar.close()\n",
    "    print(\"Extracted objects and stored. Location: \",data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dkube/work/workspace/pets_detection/data\n",
      "['/home/dkube/work/workspace/pets_detection/data/annotations.tar.gz', '/home/dkube/work/workspace/pets_detection/data/images.tar.gz']\n",
      "/home/dkube/work/workspace/pets_detection/data/annotations.tar.gz\n",
      "/home/dkube/work/workspace/pets_detection/data/images.tar.gz\n",
      "Extracted objects and stored. Location:  /home/dkube/work/workspace/pets_detection/data\n"
     ]
    }
   ],
   "source": [
    "extract(data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving some images for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(source,destination):\n",
    "    image_list=['Abyssinian_1.jpg','Abyssinian_10.jpg','Abyssinian_100.jpg']\n",
    "    for i in image_list:\n",
    "        copyfile(os.path.join(source,i),os.path.join(destination, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images(data_dir_path+\"/images\",data_dir_path+\"/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving xml to test_annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_xml(source,destination):\n",
    "    xml_list=['Abyssinian_1.xml','Abyssinian_10.xml','Abyssinian_100.xml']\n",
    "    for i in xml_list:\n",
    "        copyfile(os.path.join(source,i),os.path.join(destination, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_xml(data_dir_path+\"/annotations/xmls\",data_dir_path+\"/test_annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensorflow records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /home/dkube/work/workspace/pets_detection/data/annotations/train.record\n"
     ]
    }
   ],
   "source": [
    "!python /home/dkube/work/workspace/pets_detection/generate_tfrecord.py -x /home/dkube/work/workspace/pets_detection/data/images -l /home/dkube/work/workspace/pets_detection/pet_label_map.pbtxt -o /home/dkube/work/workspace/pets_detection/data/annotations/train.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /home/dkube/work/workspace/pets_detection/data/test_annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python /home/dkube/work/workspace/pets_detection/generate_tfrecord.py -x /home/dkube/work/workspace/pets_detection/data/test_images -l /home/dkube/work/workspace/pets_detection/pet_label_map.pbtxt -o /home/dkube/work/workspace/pets_detection/data/test_annotations/test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/dkube/work/workspace/pets_detection/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n",
       " <http.client.HTTPMessage at 0x7f3fb608f908>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(\"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\",base_path +\"/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(base_path+'/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz')\n",
    "tar.extractall(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the following things in pipeline config\n",
    "\n",
    "\n",
    "\n",
    "#### Pipeline config file present in ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
    " \n",
    "1. num_classes: 37\n",
    "\n",
    "2. fine_tune_checkpoint:\"/home/dkube/work/workspace/pets_detection/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
    "\n",
    "3. label_map_path:\"/home/dkube/work/workspace/pets_detection/pet_label_map.pbtxt\"\n",
    "\n",
    "4. tf_record_input_reader { input_path:\"/home/dkube/work/workspace/pets_detection/data/annotations/train.record\"\n",
    "\n",
    "5. eval_input_reader {label_map_path:\"/home/dkube/work/workspace/pets_detection/pet_label_map.pbtxt\"\n",
    "shuffle: false\n",
    "num_epochs: 1\n",
    "  \n",
    " tf_record_input_reader     {input_path:\"/home/dkube/work/workspace/pets_detection/data/test_annotations/test.record\"\n",
    "    \n",
    "6. use_bfloat16: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new directory for our model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(base_path+\"/my_ssd_resnet50_v1_fpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dkube/work/workspace/pets_detection/my_ssd_resnet50_v1_fpn/pipeline.config'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy('/home/dkube/work/workspace/pets_detection/pipeline.config','/home/dkube/work/workspace/pets_detection/my_ssd_resnet50_v1_fpn/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing local devices since in-graph multi-worker training with `MirroredStrategy` is not supported in eager mode. TF_CONFIG will be ignored when when initializing `MirroredStrategy`.\n",
      "I1015 11:47:25.657989 140384311572288 mirrored_strategy.py:302] Initializing local devices since in-graph multi-worker training with `MirroredStrategy` is not supported in eager mode. TF_CONFIG will be ignored when when initializing `MirroredStrategy`.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1015 11:47:26.359178 140384311572288 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I1015 11:47:26.364014 140384311572288 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1015 11:47:26.364173 140384311572288 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/dkube/work/workspace/pets_detection/data/annotations/train.record']\n",
      "I1015 11:47:26.618119 140384311572288 dataset_builder.py:148] Reading unweighted datasets: ['/home/dkube/work/workspace/pets_detection/data/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/dkube/work/workspace/pets_detection/data/annotations/train.record']\n",
      "I1015 11:47:26.620444 140384311572288 dataset_builder.py:77] Reading record datasets for input file: ['/home/dkube/work/workspace/pets_detection/data/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1015 11:47:26.620603 140384311572288 dataset_builder.py:78] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1015 11:47:26.620670 140384311572288 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1015 11:47:26.624102 140384311572288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1015 11:47:26.660987 140384311572288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1015 11:47:34.106841 140384311572288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1015 11:47:37.062683 140384311572288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1015 11:47:38.986331 140384311572288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:262: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "!python /home/dkube/work/workspace/pets_detection/model_main_tf2.py --model_dir=/home/dkube/work/workspace/pets_detection/my_ssd_resnet50_v1_fpn --pipeline_config_path=/home/dkube/work/workspace/pets_detection/my_ssd_resnet50_v1_fpn/pipeline.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
