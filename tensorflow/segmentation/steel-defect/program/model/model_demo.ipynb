{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow.keras.backend import pow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from keras.utils import generic_utils, get_file\n",
    "\n",
    "import pickle, json\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(callback, names, logs, batch_no):\n",
    "    for name, value in zip(names, logs):\n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = value\n",
    "        summary_value.tag = name\n",
    "        callback.writer.add_summary(summary, batch_no)\n",
    "        callback.writer.flush()\n",
    "\n",
    "def rle_to_mask(rle_string,height,width):\n",
    "    rows, cols = height, width\n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rleNumbers = [int(numstring) for numstring in rle_string.split(' ')]\n",
    "        rlePairs = np.array(rleNumbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "        for index,length in rlePairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_act(x, act=True):\n",
    "    'batch normalization layer with an optinal activation layer'\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
    "    'convolutional layer which always uses the batch normalization layer'\n",
    "    conv = bn_act(x)\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "    return conv\n",
    "\n",
    "def stem(x, filters, kernel_size=3, padding='same', strides=1):\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size, padding, strides)\n",
    "    shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    output = Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
    "    res = conv_block(x, filters, k_size, padding, strides)\n",
    "    res = conv_block(res, filters, k_size, padding, 1)\n",
    "    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    output = Add()([shortcut, res])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_concat_block(x, xskip):\n",
    "    u = UpSampling2D((2,2))(x)\n",
    "    c = Concatenate()([u, xskip])\n",
    "    return c\n",
    "\n",
    "def ResUNet(img_h, img_w):\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = Input((img_h, img_w, 1))\n",
    "    \n",
    "    ## Encoder\n",
    "    e0 = inputs\n",
    "    e1 = stem(e0, f[0])\n",
    "    e2 = residual_block(e1, f[1], strides=2)\n",
    "    e3 = residual_block(e2, f[2], strides=2)\n",
    "    e4 = residual_block(e3, f[3], strides=2)\n",
    "    e5 = residual_block(e4, f[4], strides=2)\n",
    "    \n",
    "    ## Bridge\n",
    "    b0 = conv_block(e5, f[4], strides=1)\n",
    "    b1 = conv_block(b0, f[4], strides=1)\n",
    "    \n",
    "    ## Decoder\n",
    "    u1 = upsample_concat_block(b1, e4)\n",
    "    d1 = residual_block(u1, f[4])\n",
    "    \n",
    "    u2 = upsample_concat_block(d1, e3)\n",
    "    d2 = residual_block(u2, f[3])\n",
    "    \n",
    "    u3 = upsample_concat_block(d2, e2)\n",
    "    d3 = residual_block(u3, f[2])\n",
    "    \n",
    "    u4 = upsample_concat_block(d3, e1)\n",
    "    d4 = residual_block(u4, f[1])\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(4, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = Flatten()(y_true)\n",
    "    y_pred_f = Flatten()(y_pred)\n",
    "    intersection = reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.7\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky_loss(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return tf.keras.backend.pow((1-pt_1), gamma)\n",
    "\n",
    "def get_batch_data(batch_df, inp_dir, img_h, img_w):\n",
    "    b_size = len(batch_df)\n",
    "    X = np.empty((b_size, img_h, img_w, 1))\n",
    "    Y = np.empty((b_size, img_h, img_w, 4))\n",
    "    for i in range(b_size):\n",
    "        filename = batch_df.iloc[i]['ImageId']\n",
    "        x = cv2.imread(inp_dir + 'images/' + filename, 0)\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        x -= x.mean()\n",
    "        x /= x.std()\n",
    "        \n",
    "        mask = np.empty((img_h, img_w, 4))\n",
    "        rle = batch_df.iloc[i]['EncodedPixels']\n",
    "        for idm, image_class in enumerate([1,2,3,4]):\n",
    "            if batch_df.iloc[i]['ClassId'] == image_class:\n",
    "                class_mask = rle_to_mask(rle, width=img_w, height=img_h)\n",
    "            else:\n",
    "                class_mask = np.zeros((img_w, img_h))\n",
    "\n",
    "            class_mask_resized = cv2.resize(class_mask, (img_w,img_h))\n",
    "            mask[...,idm] = class_mask_resized\n",
    "        y = mask\n",
    "        y = (y > 0).astype(np.float32)\n",
    "        \n",
    "        \n",
    "        X[i,] = x.reshape(img_h, img_w, 1)\n",
    "        Y[i,] = y\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required in py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--epochs\", dest = 'epochs', type = int, default = 1, help=\"no. of epochs\")\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('DKUBE_JOB_CLASS',None) == 'notebook':\n",
    "    OUT_DIR = \"inf_model/\"\n",
    "    DATA_PATH = \"/opt/dkube/input/\"\n",
    "    if os.path.exists('inf_model'):\n",
    "        shutil.rmtree('inf_model')\n",
    "    if not os.path.exists('inf_model'):\n",
    "        os.makedirs('inf_model')\n",
    "    epochs = 1\n",
    "else:\n",
    "    OUT_DIR = \"/opt/dkube/output/\"\n",
    "    DATA_PATH = \"/opt/dkube/input/\"\n",
    "    epochs = args.epochs\n",
    "\n",
    "\n",
    "MODEL_DIR = OUT_DIR + 'model/'\n",
    "LOG_DIR = MODEL_DIR + 'logs/'\n",
    "METRIC_PATH = OUT_DIR + 'metrics/'\n",
    "INF_EXPORT_PATH =  OUT_DIR#MODEL_DIR + 'inf_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 08:40:14.259579 140649965004608 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Training on CPU****************\n",
      "Creating model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/dkube/work/workspace/steel/model/weights_110.h5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_w = 800 # resized weidth\n",
    "img_h = 256 # resized height\n",
    "batch_size = 12\n",
    "k_size = 3 # kernel size 3x3\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"****************Training on GPU****************\")\n",
    "else:\n",
    "    print(\"****************Training on CPU****************\")\n",
    "\n",
    "print(\"Creating model\")\n",
    "model = ResUNet(img_h=img_h, img_w=img_w)\n",
    "\n",
    "weights_url = \"https://raw.githubusercontent.com/oneconvergence/dkube-examples/model-weights/steel/weights_110.h5\"\n",
    "get_file('weights_110.h5', weights_url, cache_subdir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr = 0.02, epsilon = 0.01)\n",
    "model.compile(optimizer=adam, loss=focal_tversky_loss, metrics=[tversky])\n",
    "model.load_weights('weights_110.h5')\n",
    "\n",
    "print(\"Loading data\")\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "no_of_samples = len(train_df)\n",
    "no_of_pass = int(no_of_samples/batch_size)\n",
    "\n",
    "callback = TensorBoard(LOG_DIR)\n",
    "callback.set_model(model)\n",
    "train_names = ['train_loss', 'train_tversky']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training, no of batches per epoch are  532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 08:40:21.401129 140649965004608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  1 , loss =  0.214661 tversky_dist =  0.8714701\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training, no of batches per epoch are \", no_of_pass)\n",
    "for each_epoch in range(epochs):\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    idx = 0\n",
    "    pass_count = 1\n",
    "    train_metrics = []\n",
    "    for each_pass in range(1,2):\n",
    "        x, y = get_batch_data(train_df[idx:each_pass*batch_size], DATA_PATH, img_h, img_w)\n",
    "        logs = model.train_on_batch(x=x, y= y)\n",
    "        write_log(callback, train_names, logs, each_epoch)\n",
    "        idx = each_pass*batch_size\n",
    "        train_metrics.append(logs)\n",
    "    train_metrics = np.asarray(train_metrics)\n",
    "    train_metrics = np.average(train_metrics, axis=0)\n",
    "    print('Epoch = ', each_epoch+1, ', loss = ',train_metrics[0], 'tversky_dist = ', train_metrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 256, 800, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feadd254c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If doesn't come in first time, run the cell again\n",
    "from matplotlib import pyplot as plt\n",
    "y = cv2.cvtColor(pred[0], cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize = (20,80))\n",
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 08:42:06.587368 140649965004608 deprecation.py:323] From <ipython-input-13-cd1c9f4d61c2>:27: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "W0707 08:42:06.589291 140649965004608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, version =  1\n"
     ]
    }
   ],
   "source": [
    "############### Writing Metrics ##########################\n",
    "metrics = []\n",
    "metric_names = ['train_loss', 'train_tversky']\n",
    "if not tf.io.gfile.exists(METRIC_PATH):\n",
    "    tf.io.gfile.makedirs(METRIC_PATH)\n",
    "for i in range(2):\n",
    "    temp = {}\n",
    "    temp['class'] = 'scalar'\n",
    "    temp['name'] = metric_names[i]\n",
    "    temp['value'] = str(train_metrics[i])\n",
    "    metrics.append(temp)\n",
    "metrics = {'metrics':metrics}\n",
    "with open(METRIC_PATH + 'metrics.json', 'w') as outfile:\n",
    "    json.dump(metrics, outfile, indent=4)\n",
    "############### Saving Model ###############################\n",
    "version = 0\n",
    "if not tf.io.gfile.exists(INF_EXPORT_PATH):\n",
    "    tf.io.gfile.makedirs(INF_EXPORT_PATH)\n",
    "version = 1\n",
    "model.save(MODEL_DIR + 'weights.h5')\n",
    "tf.keras.backend.set_learning_phase(0)  # Ignore dropout at inference\n",
    "with tf.keras.backend.get_session() as sess:\n",
    "    tf.saved_model.simple_save(\n",
    "        sess,\n",
    "        INF_EXPORT_PATH + str(version),\n",
    "        inputs={'input': model.input},\n",
    "        outputs={'output': model.output})\n",
    "print(\"Model saved, version = \", version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
